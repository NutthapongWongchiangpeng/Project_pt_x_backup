{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import hashlib\n",
    "import io\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "\n",
    "from lxml import etree\n",
    "#import numpy as np\n",
    "#import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "#import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "    raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils.np_box_ops import iou\n",
    "\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('data_dir', '', 'Location of root directory')\n",
    "\n",
    "flags.DEFINE_string('output_dir', 'C:/Users/LOLiCON/Desktop/obj_detect', 'Path output')\n",
    "\n",
    "\n",
    "flags.DEFINE_string('label_map_path', 'C:/Users/LOLiCON/Desktop/obj_detect/detrac_label_map.pbtxt',\n",
    "                           'Path to label map proto.')\n",
    "\n",
    "#\n",
    "FLAGS = flags.FLAGS\n",
    "training_path='D:/DataSet/Insight-MVT_Annotation_Train'\n",
    "\n",
    "\n",
    "data_dir_path='D:/DataSet'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_to_tf_example(data,\n",
    "                       label_map_dict,\n",
    "                       image_subdirectory,\n",
    "                       bbox,\n",
    "                       ignore_difficult_instances=False):\n",
    "    img_path = os.path.join(image_subdirectory,data)\n",
    "    \n",
    "    with tf.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = PIL.Image.open(encoded_jpg_io)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    width,height = image.size\n",
    "    xmins = []\n",
    "    ymins = []\n",
    "    xmaxs = []\n",
    "    ymaxs = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    truncated = []\n",
    "    poses = []\n",
    "    difficult_obj = []\n",
    "\n",
    "    for target in bbox.findall('target'):\n",
    "        a = target.find('box')\n",
    "        b = target.find('attribute')\n",
    "        \n",
    "        xmin= int(float(a.attrib.get('left')))\n",
    "        ymin= int(float(a.attrib.get('top')))\n",
    "        xmax= int(float(a.attrib.get('width')) + xmin)\n",
    "        ymax= int(float(a.attrib.get('height')) +ymin)\n",
    "            \n",
    "        \n",
    "        xmins.append(xmin / width)\n",
    "        ymins.append(ymin / height)\n",
    "        xmaxs.append(xmax / width)\n",
    "        ymaxs.append(ymax / height)\n",
    "        class_name = b.attrib.get('vehicle_type')\n",
    "        classes_text.append(class_name.encode('utf8'))\n",
    "        classes.append(label_map_dict[class_name])\n",
    "        \n",
    "\n",
    "    \n",
    "    #print(xmins)\n",
    "    #print(img_path)\n",
    "    #print(class_name)\n",
    "    feature_dict = {\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(\n",
    "          data.encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(\n",
    "          data.encode('utf8')),\n",
    "      'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "      'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "  }\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tf_record(label_map_dict,\n",
    "                     annotations_dir,\n",
    "                     image_dir,\n",
    "                     excalibur,\n",
    "                     data_folder):\n",
    "\n",
    "    \n",
    "\n",
    "    xml_path = os.path.join(annotations_dir, data_folder+'.xml')\n",
    "\n",
    "    train_output_path = os.path.join(FLAGS.output_dir, 'detrac_train_only_1.record')\n",
    "    val_output_path = os.path.join(FLAGS.output_dir, 'detrac_val_only_1.record')\n",
    "        \n",
    "        #with tf.gfile.GFile(xml_path, 'r') as fid:\n",
    "    \n",
    "            #xml_str = fid.read()\n",
    "        #xml = etree.fromstring(xml_str)\n",
    "        #data = dataset_util.recursive_parse_xml_to_dict(xml)\n",
    "        #print(data['sequence'])\n",
    "    txtfile=dataset_util.read_examples_list(excalibur+'/'+data_folder+'.txt')\n",
    "    \n",
    "    num_examples = len(txtfile)\n",
    "    num_train = int(0.8 * num_examples)\n",
    "    list_train_val=[]\n",
    "    count_train_val=0\n",
    "    for a in txtfile:\n",
    "        if(count_train_val<num_train):\n",
    "            list_train_val.append(1) #train \n",
    "        else:\n",
    "            list_train_val.append(0) # val\n",
    "        count_train_val+=1\n",
    "    random.seed(42)\n",
    "    random.shuffle(list_train_val)\n",
    "    \n",
    "    \n",
    "    print(data_folder)\n",
    "    aa=[]  \n",
    "    img_list=[]\n",
    "    tree = etree.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    i=0 \n",
    "    j=0\n",
    "    for frame in root.findall('frame'):\n",
    "        num_img= int(float(frame.attrib.get('num')))\n",
    "        target_list = frame.find('target_list')\n",
    "        aa.append(target_list)\n",
    "        img_list.append(num_img)\n",
    "        #print(num_img)\n",
    "    V=0\n",
    "    try:\n",
    "           \n",
    "        for data in txtfile: \n",
    "            if((i+1)==img_list[j]):\n",
    "                tf_example = dict_to_tf_example(data, label_map_dict, image_dir,aa[j])\n",
    "                \n",
    "                if(j<len(img_list)-1):\n",
    "                    j=j+1\n",
    "            \n",
    "                if (list_train_val[i]==0):\n",
    "                    writer = tf.python_io.TFRecordWriter(val_output_path)\n",
    "                    writer.write(tf_example.SerializeToString())\n",
    "                    writer.close()\n",
    "                    V+=1\n",
    "                    print(V)\n",
    "                else:\n",
    "                    writer = tf.python_io.TFRecordWriter(train_output_path)\n",
    "                    writer.write(tf_example.SerializeToString())\n",
    "                    writer.close()\n",
    "            i=i+1\n",
    "    except ValueError:\n",
    "        logging.warning('Invalid example: %s, ignoring.', xml_path)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "train\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_tf_record() takes 5 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-238d35207927>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-238d35207927>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mimage_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mcreate_tf_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_output_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_map_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexcalibur\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;31m#image_dir = os.path.join(training_path, data_folder)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m#create_tf_record(label_map_dict, annotations_dir,image_dir,excalibur,data_folder)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: create_tf_record() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "def main(_):\n",
    "    data_dir = FLAGS.data_dir\n",
    "    label_map_dict = label_map_util.get_label_map_dict(FLAGS.label_map_path)\n",
    "\n",
    "   \n",
    "    logging.info('Reading from DETRAC dataset.')\n",
    "    \n",
    "    \n",
    "    annotations_dir = os.path.join(data_dir_path, 'DETRAC-Train-Annotations-XML')\n",
    "\n",
    "  # Test images are not included in the downloaded data set, so we shall perform\n",
    "  # our own split.\n",
    "\n",
    "\n",
    "    train_output_path = os.path.join(FLAGS.output_dir, 'detrac_train_only_1.record')\n",
    "    val_output_path = os.path.join(FLAGS.output_dir, 'detrac_val_only_1.record')\n",
    "    \n",
    "    #for 1 view only\n",
    "    excalibur=data_dir_path+'/ua-text_file_front'\n",
    "    \n",
    "#    csv=pd.read_csv(excalibur+'/Insight-MVT_Annotation_Train.txt')\n",
    "    txtfile=dataset_util.read_examples_list(excalibur+'/Insight-MVT_Annotation_Train.txt')\n",
    "    \n",
    "    num_examples = len(txtfile)\n",
    "    num_train = int(0.9 * num_examples)\n",
    "    train_examples = txtfile[:num_train]\n",
    "    val_examples = txtfile[num_train:]\n",
    "    count = 0\n",
    "    \n",
    "    #data_folder='MVI_20011'\n",
    "    \n",
    "    for data_folder in train_examples:\n",
    "        count += 1\n",
    "        print(count)\n",
    "        print('train')\n",
    "        image_dir = os.path.join(training_path, data_folder)\n",
    "        create_tf_record(train_output_path, label_map_dict, annotations_dir,image_dir,excalibur,data_folder)\n",
    "    #image_dir = os.path.join(training_path, data_folder)\n",
    "    #create_tf_record(label_map_dict, annotations_dir,image_dir,excalibur,data_folder)\n",
    "    for data_folder in val_examples:\n",
    "        count += 1\n",
    "        print(count)\n",
    "        print('val')\n",
    "        image_dir = os.path.join(training_path, data_folder)\n",
    "        create_tf_record(val_output_path, label_map_dict, annotations_dir,image_dir,excalibur,data_folder)\n",
    "        \n",
    "  # TODO(user): Write code to read in your dataset to examples variable\n",
    "\n",
    "#  for example in examples:\n",
    "#    tf_example = create_tf_example(example)\n",
    "#    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "#  writer.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
