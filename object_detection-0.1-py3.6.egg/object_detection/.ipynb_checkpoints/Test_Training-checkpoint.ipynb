{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import hashlib\n",
    "import io\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "\n",
    "from lxml import etree\n",
    "#import numpy as np\n",
    "#import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "#import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "    raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils.np_box_ops import iou\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_string('data_dir', '', 'Location of root directory')\n",
    "\n",
    "flags.DEFINE_string('output_dir', 'C:/Users/2NP/Desktop/obj_detect', 'Path output')\n",
    "\n",
    "\n",
    "flags.DEFINE_string('label_map_path', 'C:/Users/2NP/Desktop/obj_detect/detrac_label_map.pbtxt',\n",
    "                           'Path to label map proto.')\n",
    "\n",
    "#\n",
    "FLAGS = flags.FLAGS\n",
    "training_path='C:/Users/2NP/Desktop/DataSet/Insight-MVT_Annotation_Train'\n",
    "\n",
    "\n",
    "data_dir_path='C:/Users/2NP/Desktop/DataSet'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_tf_example(data,\n",
    "                       label_map_dict,\n",
    "                       image_subdirectory,\n",
    "                       bbox,\n",
    "                       ignore_difficult_instances=False):\n",
    "    img_path = os.path.join(image_subdirectory,data)\n",
    "    with tf.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = PIL.Image.open(encoded_jpg_io)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    width,height = image.size\n",
    "\n",
    "    xmins = []\n",
    "    ymins = []\n",
    "    xmaxs = []\n",
    "    ymaxs = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    truncated = []\n",
    "    poses = []\n",
    "    difficult_obj = []\n",
    "\n",
    "   \n",
    "    for target in bbox.findall('target'):\n",
    "        a = target.find('box')\n",
    "        b = target.find('attribute')\n",
    "       \n",
    "        \n",
    "        \n",
    "        xmin= int(float(a.attrib.get('left')))\n",
    "        ymin= int(float(a.attrib.get('top')))\n",
    "        xmax= int(float(a.attrib.get('width')) + xmin)\n",
    "        ymax= int(float(a.attrib.get('height')) +ymin)\n",
    "\n",
    "        \n",
    "        \n",
    "        xmins.append(xmin / width)\n",
    "        ymins.append(ymin / height)\n",
    "        xmaxs.append(xmax / width)\n",
    "        ymaxs.append(ymax / height)\n",
    "        class_name = b.attrib.get('vehicle_type')\n",
    "        classes_text.append(class_name.encode('utf8'))\n",
    "        classes.append(label_map_dict[class_name])\n",
    "\n",
    "        \n",
    "   \n",
    "    feature_dict = {\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(\n",
    "          data.encode('utf8')),\n",
    "      'image/source_id': dataset_util.bytes_feature(\n",
    "          data.encode('utf8')),\n",
    "      'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "      'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "      'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "      'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "      'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "  }\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(output_filename,\n",
    "                     label_map_dict,\n",
    "                     annotations_dir,\n",
    "                     image_dir,\n",
    "                     examples):\n",
    "    writer = tf.python_io.TFRecordWriter(output_filename)\n",
    "    for idx, example in enumerate(examples):\n",
    "        if idx % 100 == 0:\n",
    "            logging.info('On image %d of %d', idx, len(examples))\n",
    "        xml_path = os.path.join(annotations_dir, example)\n",
    "\n",
    "        if not os.path.exists(xml_path):\n",
    "            logging.warning('Could not find %s, ignoring example.', xml_path)\n",
    "            continue\n",
    "        \n",
    "        #with tf.gfile.GFile(xml_path, 'r') as fid:\n",
    "    \n",
    "            #xml_str = fid.read()\n",
    "        #xml = etree.fromstring(xml_str)\n",
    "        #data = dataset_util.recursive_parse_xml_to_dict(xml)\n",
    "        #print(data['sequence'])\n",
    "        csv=pd.read_csv(image_dir+'/MVI_20011.csv')\n",
    "        aa=[]\n",
    "        i=0\n",
    "        tree = etree.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        for frame in root.findall('frame'):\n",
    "            target_list = frame.find('target_list')\n",
    "            aa.append(target_list)\n",
    "                \n",
    "        try:\n",
    "           \n",
    "            for data in csv:\n",
    "                tf_example = dict_to_tf_example(data, label_map_dict, image_dir,aa[i])\n",
    "                i+=1\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "        except ValueError:\n",
    "            logging.warning('Invalid example: %s, ignoring.', xml_path)\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main(_):\n",
    "    data_dir = FLAGS.data_dir\n",
    "    label_map_dict = label_map_util.get_label_map_dict(FLAGS.label_map_path)\n",
    "\n",
    "    logging.info('Reading from DETRAC dataset.')\n",
    "    image_dir = os.path.join(training_path, 'MVI_20011')\n",
    "    annotations_dir = os.path.join(data_dir_path, 'DETRAC-Train-Annotations-XML')\n",
    "    examples_path = os.path.join(annotations_dir, 'DETRAC-Train-Annotations-XML.csv')\n",
    "    examples_list = dataset_util.read_examples_list(examples_path)\n",
    "\n",
    "  # Test images are not included in the downloaded data set, so we shall perform\n",
    "  # our own split.\n",
    "   \n",
    "    num_examples = len(examples_list)\n",
    "    num_train = int(0.7 * num_examples)\n",
    "    train_examples = examples_list[:num_train]\n",
    "    val_examples = examples_list[num_train:]\n",
    "    logging.info('%d training and %d validation examples.',\n",
    "               len(train_examples), len(val_examples))\n",
    "\n",
    "    train_output_path = os.path.join(FLAGS.output_dir, 'detrac_train.record')\n",
    "    val_output_path = os.path.join(FLAGS.output_dir, 'detrac_val.record')\n",
    "    \n",
    "    create_tf_record(train_output_path, label_map_dict, annotations_dir,\n",
    "                   image_dir, train_examples)\n",
    "    create_tf_record(val_output_path, label_map_dict, annotations_dir,\n",
    "                   image_dir, val_examples)\n",
    "  \n",
    "  # TODO(user): Write code to read in your dataset to examples variable\n",
    "\n",
    "#  for example in examples:\n",
    "#    tf_example = create_tf_example(example)\n",
    "#    writer.write(tf_example.SerializeToString())\n",
    "\n",
    "#  writer.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
